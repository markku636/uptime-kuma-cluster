# Uptime Kuma Cluster

<div align="center">

![OpenResty](https://img.shields.io/badge/OpenResty-Nginx-green?style=flat-square)
![Lua](https://img.shields.io/badge/Lua-5.1-blue?style=flat-square)
![MariaDB](https://img.shields.io/badge/MariaDB-10.x-orange?style=flat-square)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=flat-square)

**é«˜å¯ç”¨ Uptime Kuma é›†ç¾¤è§£æ±ºæ–¹æ¡ˆ | High-Availability Uptime Kuma Cluster Solution**

[å¿«é€Ÿé–‹å§‹ Quick Start](#-å¿«é€Ÿé–‹å§‹quick-start) â€¢ [åŠŸèƒ½ç‰¹æ€§ Features](#-åŠŸèƒ½ç‰¹æ€§features) â€¢ [API æ–‡ä»¶ API Docs](#-api-æ¥å£api-endpoints) â€¢ [éƒ¨ç½²æŒ‡å— Deployment](#-éƒ¨ç½²æŒ‡å—deployment-guide)

</div>

-----

## ğŸ¯ ç³»çµ±æ¦‚è¿° | Overview

æœ¬å°ˆæ¡ˆæ˜¯ä¸€å€‹åŸºæ–¼ **Nginx OpenResty** çš„æ™ºèƒ½è² è¼‰å¹³è¡¡å’Œå¥åº·æª¢æŸ¥ç³»çµ±ï¼Œå°ˆç‚º **Uptime Kuma** çš„å¤šç¯€é»é›†ç¾¤éƒ¨ç½²è€Œè¨­è¨ˆã€‚ç³»çµ±é€é Lua è…³æœ¬å¯¦ç¾äº†æ‡‰ç”¨å±¤ç´šçš„é‚è¼¯ï¼Œå…·å‚™è‡ªå‹•æ•…éšœæª¢æ¸¬ã€æ•…éšœè½‰ç§»ï¼ˆFailoverï¼‰ã€æ™ºèƒ½è² è¼‰åˆ†é…ä»¥åŠç›£æ§ä»»å‹™çš„é‡æ–°å¹³è¡¡ï¼ˆRebalancingï¼‰åŠŸèƒ½ï¼Œç¢ºä¿ç›£æ§æœå‹™çš„é«˜å¯ç”¨æ€§ï¼ˆHAï¼‰ã€‚

> This project is an intelligent load balancing and health check system based on **Nginx OpenResty**, designed for multi-node cluster deployment of **Uptime Kuma**. The system implements application-level logic through Lua scripts, featuring automatic fault detection, failover, intelligent load distribution, and monitor task rebalancing to ensure high availability (HA) of monitoring services.

ğŸ“– éƒ¨è½æ ¼è©³è§£ï¼ˆæ¶æ§‹èˆ‡å¯¦ä½œå¿ƒæ³•ï¼‰| Blog Post: https://blog.markkulab.net/implement-uptime-kuma-cluster-vibe-coding/

-----

## ğŸš€ å¿«é€Ÿé–‹å§‹ | Quick Start

### å‰ç½®éœ€æ±‚ | Prerequisites
- Docker Desktop å·²å®‰è£ | Docker Desktop installed
- Node.js 18+ å·²å®‰è£ | Node.js 18+ installed  
- PowerShell 5.1ï¼ˆWindows é è¨­ï¼‰| PowerShell 5.1 (Windows default)

### å•Ÿå‹•é›†ç¾¤ | Start Cluster

```powershell
# æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œ | Run in project root
docker compose -f docker-compose-cluster.yaml up -d --build

# æŸ¥çœ‹å®¹å™¨ç‹€æ…‹ | Check container status
docker ps
```

> ğŸ’¡ æç¤ºï¼šå·²å®‰è£ Docker Desktop æ™‚ï¼Œç›´æ¥ä½¿ç”¨ `docker compose` æŒ‡ä»¤å³å¯ã€‚
> Tip: With Docker Desktop installed, just use `docker compose` command directly.

### å–®æ©Ÿé–‹ç™¼æ¨¡å¼ | Single Node Development

```powershell
# å¾Œç«¯ Backend (Node.js)
node start-server.js

# å‰ç«¯ Frontend (Vite)
npm run dev
```

### é©—è­‰å®‰è£ | Verify Installation

ä½¿ç”¨ VS Code REST Client é–‹å•Ÿ `set-up.http` æ¸¬è©¦ï¼š
> Open `set-up.http` with VS Code REST Client to test:

```http
GET http://localhost:8084/health              # OpenResty å¥åº·ç‹€æ…‹ | Health status
GET http://localhost:8084/lb/health           # é›†ç¾¤å¥åº·ç‹€æ…‹ | Cluster health
GET http://localhost:8084/lb/available-nodes  # å¯ç”¨ç¯€é»åˆ—è¡¨ | Available nodes
```

-----

## âš¡ åŠŸèƒ½ç‰¹æ€§ | Features

| ç‰¹æ€§ Feature | æè¿° Description |
| :--- | :--- |
| **âš–ï¸ å…©éšæ®µæ™ºèƒ½è² è¼‰å¹³è¡¡** | æ¡ç”¨ access + balancer å…©éšæ®µæ¶æ§‹ï¼šåœ¨ `access_by_lua` éšæ®µå®Œæˆ DB æŸ¥è©¢èˆ‡ DNS è§£æï¼Œåœ¨ `balancer_by_lua` éšæ®µè¨­ç½®ä¸Šæ¸¸ç¯€é»ã€‚ |
| Two-Phase Smart Load Balancing | Uses access + balancer two-phase architecture: DB queries and DNS resolution in `access_by_lua`, upstream node selection in `balancer_by_lua`. |
| **ğŸ’“ ä¸»å‹•å¥åº·æª¢æŸ¥** | ç³»çµ±æ¯ **30 ç§’**å°ç¯€é»é€²è¡Œä¸»å‹•å¥åº·æª¢æŸ¥ï¼Œçµæœå¯«å…¥è³‡æ–™åº« `node` è¡¨ã€‚ |
| Active Health Check | System performs active health checks on nodes every **30 seconds**, results written to database `node` table. |
| **ğŸ”„ è‡ªå‹•æ•…éšœè½‰ç§»** | ç•¶æª¢æ¸¬åˆ°ç¯€é»æ•…éšœï¼ˆé€£çºŒ 3 æ¬¡å¤±æ•—ï¼‰æ™‚ï¼Œè‡ªå‹•å°‡è©²ç¯€é»çš„ç›£æ§ä»»å‹™è½‰ç§»è‡³å…¶ä»–å¥åº·ç¯€é»ã€‚ |
| Auto Failover | When node failure is detected (3 consecutive failures), automatically transfers monitoring tasks to other healthy nodes. |
| **ğŸ›¡ï¸ ç¯€é»æ¢å¾©ç®¡ç†** | ç¯€é»æ¢å¾©å¥åº·å¾Œï¼Œè‡ªå‹•é‚„åŸå…ˆå‰è½‰ç§»èµ°çš„ç›£æ§ä»»å‹™ã€‚ |
| Node Recovery Management | After node recovers, automatically restores previously transferred monitoring tasks. |
| **ğŸ“Š ç¯€é»å®¹é‡æŸ¥è©¢** | é€é `/lb/capacity` API æŸ¥è©¢æ¯å€‹ç¯€é»ç•¶å‰çš„ç›£æ§æ•¸é‡èˆ‡ä½¿ç”¨ç‡ã€‚ |
| Node Capacity Query | Query each node's current monitor count and utilization via `/lb/capacity` API. |
| **ğŸ¯ å›ºå®šç¯€é»è·¯ç”±ï¼ˆæ–°åŠŸèƒ½ï¼‰** | é€é Cookie å°‡è«‹æ±‚å›ºå®šè·¯ç”±åˆ°æŒ‡å®šç¯€é»ï¼Œæ–¹ä¾¿é–‹ç™¼èª¿è©¦ã€‚ |
| Fixed Node Routing (New) | Route requests to a specific node via Cookie, convenient for development and debugging. |
| **ğŸŒ Docker DNS æ•´åˆ** | ä½¿ç”¨ Docker å…§å»º DNS (127.0.0.11) è§£ææœå‹™åç‚º IPã€‚ |
| Docker DNS Integration | Uses Docker built-in DNS (127.0.0.11) to resolve service names to IP. |

-----

## ğŸ“¦ ç›®éŒ„å°è¦½ | Directory Structure

| ç›®éŒ„/æª”æ¡ˆ | èªªæ˜ Description |
| :--- | :--- |
| `docker-compose-cluster.yaml` | å•Ÿå‹•å¤šç¯€é» Uptime Kuma + OpenResty çš„ Compose æª” |
| `nginx/`, `nginx.conf` | OpenResty/Nginx ä¸»è¨­å®šèˆ‡ç«™å°è¨­å®š |
| `lua/` | è² è¼‰å¹³è¡¡èˆ‡å¥åº·æª¢æŸ¥ Lua è…³æœ¬ |
| `server/` | Kuma ä¼ºæœç«¯é‚è¼¯ï¼ˆèªè­‰ã€æ’ç¨‹ã€é€šçŸ¥ç­‰ï¼‰ |
| `db/` | è³‡æ–™åº«åˆå§‹åŒ–èˆ‡é·ç§»è…³æœ¬ï¼ˆKnexï¼‰ |
| `extra/` | è¼”åŠ©å·¥å…·èˆ‡è…³æœ¬ |
| `public/`, `src/` | å‰ç«¯è³‡æºèˆ‡ç¨‹å¼ç¢¼ |
| `API_DOCUMENTATION.md` | HTTP API è©³ç´°èªªæ˜èˆ‡ä½¿ç”¨ç¯„ä¾‹ |

-----

## ğŸ¯ å›ºå®šç¯€é»è·¯ç”± | Fixed Node Routing

æ­¤åŠŸèƒ½å…è¨±é–‹ç™¼è€…é€é Cookie å°‡æ‰€æœ‰è«‹æ±‚å›ºå®šè·¯ç”±åˆ°æŒ‡å®šçš„ç¯€é»ï¼Œæ–¹ä¾¿èª¿è©¦å’Œæ¸¬è©¦ã€‚æ¸…é™¤ Cookie å¾Œå³æ¢å¾©æ­£å¸¸çš„è² è¼‰å‡è¡¡ã€‚

> This feature allows developers to route all requests to a specific node via Cookie for debugging and testing. Clearing the Cookie restores normal load balancing.

### ğŸ”— ç°¡æ˜“ URL æ“ä½œ | Simple URL Operations

æœ€ç°¡å–®çš„æ–¹å¼ï¼šç›´æ¥åœ¨ç€è¦½å™¨è¨ªå•ä»¥ä¸‹ URLï¼š
> The easiest way: visit the following URLs directly in your browser:

| æ“ä½œ Action | URL | èªªæ˜ Description |
| :--- | :--- | :--- |
| è¨­å®šåˆ° node1 | `GET /lb/fixed-node/node1` | æ‰€æœ‰è«‹æ±‚è·¯ç”±åˆ° node1 / Route all requests to node1 |
| è¨­å®šåˆ° node2 | `GET /lb/fixed-node/node2` | æ‰€æœ‰è«‹æ±‚è·¯ç”±åˆ° node2 / Route all requests to node2 |
| è¨­å®šåˆ° node3 | `GET /lb/fixed-node/node3` | æ‰€æœ‰è«‹æ±‚è·¯ç”±åˆ° node3 / Route all requests to node3 |
| **æ¸…é™¤è¨­å®š** | `GET /lb/clear-fixed-node` | æ¢å¾©è² è¼‰å‡è¡¡ / Restore load balancing |

### ğŸ“ ä½¿ç”¨ç¯„ä¾‹ | Usage Example

```bash
# 1. æŸ¥çœ‹å¯ç”¨ç¯€é» | View available nodes
curl http://localhost:8084/lb/available-nodes

# 2. è¨­å®šå›ºå®šç¯€é»ï¼ˆç€è¦½å™¨ç›´æ¥è¨ªå•ï¼‰| Set fixed node (visit in browser)
# http://localhost:8084/lb/fixed-node/node2

# 3. é©—è­‰è¨­å®š | Verify setting
curl http://localhost:8084/lb/fixed-node-status

# 4. æ¸…é™¤è¨­å®šï¼ˆç€è¦½å™¨ç›´æ¥è¨ªå•ï¼‰| Clear setting (visit in browser)
# http://localhost:8084/lb/clear-fixed-node
```

### ğŸ”§ API æ“ä½œ | API Operations

è‹¥éœ€ç¨‹å¼åŒ–æ“ä½œï¼Œå¯ä½¿ç”¨ JSON APIï¼š
> For programmatic operations, use JSON API:

```bash
# è¨­å®šå›ºå®šç¯€é» | Set fixed node
curl -X POST http://localhost:8084/lb/set-fixed-node \
  -H "Content-Type: application/json" \
  -d '{"node": "node2", "expires": 604800}'

# æ¸…é™¤å›ºå®šç¯€é» | Clear fixed node
curl -X POST http://localhost:8084/lb/clear-fixed-node

# æŸ¥çœ‹ç‹€æ…‹ | View status
curl http://localhost:8084/lb/fixed-node-status
```

### ğŸ“Š Response æ¨™é ­ | Response Headers

è¨­å®šå›ºå®šç¯€é»å¾Œï¼Œæ‰€æœ‰å›æ‡‰æœƒåŒ…å«ä»¥ä¸‹æ¨™é ­ï¼š
> After setting a fixed node, all responses will include these headers:

| Header | å€¼ Value | èªªæ˜ Description |
| :--- | :--- | :--- |
| `X-Routed-Via` | `fixed-node` æˆ– `load-balancer` | è·¯ç”±æ–¹å¼ / Routing method |
| `X-Routed-To` | `uptime-kuma-node2` | å¯¦éš›è·¯ç”±åˆ°çš„ç¯€é» / Actual routed node |

### âš ï¸ æ³¨æ„äº‹é … | Notes

- Cookie åç¨±ï¼š`KUMA_FIXED_NODE`
- é è¨­æœ‰æ•ˆæœŸï¼š7 å¤©ï¼ˆå¯é€é API è‡ªè¨‚ï¼‰
- è‹¥æŒ‡å®šçš„ç¯€é»é›¢ç·šï¼Œç³»çµ±æœƒè‡ªå‹•æ¸…é™¤ Cookie ä¸¦æ¢å¾©è² è¼‰å‡è¡¡
- æ­¤åŠŸèƒ½ä¸»è¦ç”¨æ–¼é–‹ç™¼èª¿è©¦ï¼Œç”Ÿç”¢ç’°å¢ƒè«‹è¬¹æ…ä½¿ç”¨
- æª¢æŸ¥ç¯€é»ç‹€æ…‹ï¼šè¨ªå• `/lb/available-nodes`
- æ¸…é™¤è¨­å®šï¼šè¨ªå• `/lb/clear-fixed-node`

> - Cookie name: `KUMA_FIXED_NODE`
> - Default expiry: 7 days (customizable via API)
> - If the specified node goes offline, the system will automatically clear the Cookie and restore load balancing
> - This feature is mainly for development debugging, use cautiously in production
> - Check node status: visit `/lb/available-nodes`
> - Clear setting: visit `/lb/clear-fixed-node`

-----

## ğŸ—ï¸ æ¶æ§‹è¨­è¨ˆ | Architecture

### ç³»çµ±é‚è¼¯æ¶æ§‹ | System Logic Architecture

```mermaid
graph TD
    Client[Client Request] --> Nginx[Nginx OpenResty<br>Load Balancer]
    
    subgraph "Nginx Logic (Lua)"
        LB[Load Balancer]
        HC[Health Check & Failover]
    end
    
    Nginx --> LB
    Nginx --> HC
    
    LB -->|Route to Best Node| Node1
    LB -->|Route to Best Node| Node2
    LB -->|Route to Best Node| Node3
    
    HC -.->|Monitor| Node1[Uptime Kuma Node 1<br>:3001]
    HC -.->|Monitor| Node2[Uptime Kuma Node 2<br>:3002]
    HC -.->|Monitor| Node3[Uptime Kuma Node 3<br>:3003]
    
    Node1 --> DB[(MariaDB Database)]
    Node2 --> DB
    Node3 --> DB
```

### è² è¼‰å¹³è¡¡æ±ºç­–æµç¨‹ | Load Balancing Decision Flow

ï¼ˆå…©éšæ®µ Lua è·¯ç”±æ¶æ§‹ | Two-Phase Lua Routing Architectureï¼‰

ç”±æ–¼ OpenResty çš„ `balancer_by_lua*` éšæ®µæœ‰ API é™åˆ¶ï¼ˆç„¡æ³•ä½¿ç”¨ `ngx.socket.tcp()` ç­‰ cosocket APIï¼‰ï¼Œç³»çµ±æ¡ç”¨**å…©éšæ®µæ¶æ§‹**ä¾†å¯¦ç¾å‹•æ…‹è·¯ç”±ï¼š

```mermaid
sequenceDiagram
    participant Client
    participant Nginx
    participant Access[access_by_lua]
    participant Balancer[balancer_by_lua]
    participant DNS[Docker DNS]
    participant DB[(MariaDB)]
    participant Node[Uptime Kuma Node]

    Client->>Nginx: HTTP Request
    Nginx->>Access: é€²å…¥ access éšæ®µ
    Access->>DB: æŸ¥è©¢ node è¡¨å–å¾— online ç¯€é»
    DB-->>Access: è¿”å›ç¯€é»åˆ—è¡¨èˆ‡è² è¼‰
    Access->>Access: é¸æ“‡æœ€ç©ºé–’ç¯€é» (uptime-kuma-nodeX)
    Access->>DNS: è§£æ hostname ç‚º IP
    DNS-->>Access: è¿”å› IP åœ°å€
    Access->>Access: å­˜å„² IP:Port åˆ° ngx.ctx
    Access-->>Nginx: å®Œæˆé é¸
    Nginx->>Balancer: é€²å…¥ balancer éšæ®µ
    Balancer->>Balancer: å¾ ngx.ctx è®€å–é é¸çš„ IP:Port
    Balancer->>Node: set_current_peer(IP, Port)
    Node-->>Client: HTTP Response
```

#### éšæ®µèªªæ˜ | Phase Description

| éšæ®µ | Nginx Directive | å¯ç”¨ API | è·è²¬ |
|:---|:---|:---|:---|
| **Access éšæ®µ** | `access_by_lua_block` | âœ… Socketã€MySQLã€DNS è§£æ | æŸ¥è©¢ DB é¸æ“‡ç¯€é»ã€è§£æ DNS ç‚º IPã€å­˜å…¥ `ngx.ctx` |
| **Balancer éšæ®µ** | `balancer_by_lua_block` | âŒ åƒ…é™ `ngx.balancer` API | å¾ `ngx.ctx` è®€å–é é¸çµæœã€å‘¼å« `set_current_peer()` |

#### è©³ç´°æµç¨‹ | Detailed Flow

1.  **è«‹æ±‚åˆ°é”**ï¼šNginx `location` æ”¶åˆ°è«‹æ±‚ã€‚
2.  **Access éšæ®µ - é é¸ç¯€é»**ï¼š`access_by_lua_block` å‘¼å« `router.preselect_node()`ï¼š
    - é€é `pick_node_for_request()` æŸ¥è©¢è³‡æ–™åº« `node` èˆ‡ `monitor` è¡¨
    - çµ±è¨ˆæ¯å€‹ `status = 'online'` ç¯€é»ç›®å‰ `active = 1` çš„ç›£æ§æ•¸é‡
    - é¸æ“‡ã€Œç›£æ§æ•¸é‡æœ€å°‘ã€çš„ online ç¯€é»ï¼Œæ˜ å°„ç‚º Docker æœå‹™å `uptime-kuma-nodeX`
    - ä½¿ç”¨ `resty.dns.resolver` å°‡ hostname è§£æç‚º IP åœ°å€
    - å°‡ IP å’Œ Port å­˜å…¥ `ngx.ctx.upstream_host` å’Œ `ngx.ctx.upstream_port`
3.  **Balancer éšæ®µ - è¨­ç½®ç›®æ¨™**ï¼š`balancer_by_lua_block` å‘¼å« `router.get_preselected_node()`ï¼š
    - å¾ `ngx.ctx` è®€å–é é¸çš„ IP å’Œ Port
    - é€é `ngx.balancer.set_current_peer(ip, port)` è¨­ç½®å¯¦éš›ä¸Šæ¸¸ç¯€é»
4.  **å¾Œç«¯è™•ç†**ï¼šè«‹æ±‚è¢«è½‰ç™¼è‡³é¸å®šçš„ Uptime Kuma ç¯€é»ä¸¦å®Œæˆå›æ‡‰ã€‚

#### ç‚ºä»€éº¼éœ€è¦å…©éšæ®µï¼Ÿ| Why Two Phases?

OpenResty çš„ `balancer_by_lua*` éšæ®µé‹è¡Œåœ¨ Nginx çš„é€£æ¥å»ºç«‹éç¨‹ä¸­ï¼Œæ­¤æ™‚ä»¥ä¸‹ API è¢«ç¦ç”¨ï¼š
- `ngx.socket.tcp()` - ç„¡æ³•å»ºç«‹ TCP é€£æ¥ï¼ˆåŒ…æ‹¬ MySQL é€£æ¥ï¼‰
- `ngx.socket.udp()` - ç„¡æ³•é€²è¡Œ UDP é€šä¿¡
- DNS è§£æï¼ˆä¾è³´ socketï¼‰

å› æ­¤ï¼Œæ‰€æœ‰éœ€è¦ç¶²è·¯ I/O çš„æ“ä½œï¼ˆè³‡æ–™åº«æŸ¥è©¢ã€DNS è§£æï¼‰å¿…é ˆåœ¨ `access_by_lua*` éšæ®µå®Œæˆï¼Œä¸¦å°‡çµæœé€é `ngx.ctx`ï¼ˆè«‹æ±‚ç´šåˆ¥çš„ä¸Šä¸‹æ–‡ï¼‰å‚³éçµ¦ `balancer_by_lua*` éšæ®µä½¿ç”¨ã€‚

-----

## ğŸ”§ æ¨¡çµ„èªªæ˜ | Module Description

ç³»çµ±ç¶“éé‡æ§‹ï¼Œæ ¸å¿ƒé‚è¼¯ç”±ä»¥ä¸‹ 6 å€‹ Lua æ¨¡çµ„æ§‹æˆï¼š

### æ¨¡çµ„æ¶æ§‹ | Module Architecture

```
lua/
â”œâ”€â”€ config.lua         # é›†ä¸­é…ç½®ç®¡ç† (ç’°å¢ƒè®Šæ•¸ã€é è¨­å€¼)
â”œâ”€â”€ db.lua             # å…±ç”¨è³‡æ–™åº«é€£æ¥æ¨¡çµ„
â”œâ”€â”€ logger.lua         # å…±ç”¨æ—¥èªŒæ¨¡çµ„ (çµ±ä¸€æ ¼å¼ã€åˆ†é¡)
â”œâ”€â”€ middleware.lua     # ä¸­ä»‹å±¤ (access/header_filter çµ±ä¸€è™•ç†)
â”œâ”€â”€ health_check.lua   # å¥åº·æª¢æŸ¥èˆ‡ç¯€é»ç®¡ç†
â””â”€â”€ monitor_router.lua # è·¯ç”±æ±ºç­–é‚è¼¯
```

### 0\. `ngx` æ˜¯ä»€éº¼ï¼Ÿå¦‚ä½•åœ¨ OpenResty è£¡å°é  / è½‰ç™¼è«‹æ±‚

OpenResty å…§å»ºä¸€å€‹å…¨åŸŸç‰©ä»¶ `ngx`ï¼Œæä¾›ï¼š

- **è«‹æ±‚/å›æ‡‰æ§åˆ¶**ï¼š`ngx.var`ï¼ˆè®€å¯« Nginx è®Šæ•¸ï¼‰ã€`ngx.req`ï¼ˆè®€å–è«‹æ±‚ï¼‰ã€`ngx.say` / `ngx.print`ï¼ˆè¼¸å‡ºå…§å®¹ï¼‰ã€`ngx.status` / `ngx.header`ï¼ˆè¨­å®šç‹€æ…‹ç¢¼èˆ‡æ¨™é ­ï¼‰ã€`ngx.exit()`ï¼ˆçµæŸè«‹æ±‚ä¸¦å›å‚³ç‰¹å®š HTTP ç‹€æ…‹ç¢¼ï¼‰ã€‚
- **è«‹æ±‚ç´šåˆ¥ä¸Šä¸‹æ–‡**ï¼š`ngx.ctx` æ˜¯ä¸€å€‹ Lua tableï¼Œç”¨æ–¼åœ¨åŒä¸€è«‹æ±‚çš„ä¸åŒè™•ç†éšæ®µä¹‹é–“å‚³éè³‡æ–™ã€‚æœ¬å°ˆæ¡ˆç”¨å®ƒåœ¨ access éšæ®µå­˜å„²é é¸çš„ç¯€é» IPï¼Œä¾› balancer éšæ®µä½¿ç”¨ã€‚
- **è·¯ç”±èˆ‡ä¸Šæ¸¸é¸æ“‡**ï¼š
  - åœ¨ `access_by_lua_block` ä¸­é€²è¡Œ DB æŸ¥è©¢ã€DNS è§£æç­‰éœ€è¦ socket çš„æ“ä½œï¼Œä¸¦å°‡çµæœå­˜å…¥ `ngx.ctx`ã€‚
  - åœ¨ `balancer_by_lua_block` ä¸­ä½¿ç”¨ `local balancer = require "ngx.balancer"`ï¼Œå†å‘¼å« `balancer.set_current_peer(ip, port)` ä¾†**å‹•æ…‹æŒ‡å®šæ­¤è«‹æ±‚è¦æ‰“åˆ°å“ªä¸€å€‹å¾Œç«¯ç¯€é»**ã€‚æ³¨æ„ï¼šæ­¤éšæ®µåªèƒ½ä½¿ç”¨ IP åœ°å€ï¼Œä¸èƒ½ä½¿ç”¨ hostnameã€‚
  - åœ¨ `content_by_lua_block` ä¸­ç›´æ¥ç”¢ç”Ÿå›æ‡‰ï¼ˆä¾‹å¦‚ `/lb/health`ã€`/lb/capacity`ï¼‰ï¼Œä¸ç”¨å†é€é upstreamã€‚
- **è¨ˆæ™‚ã€æ’ç¨‹èˆ‡å…±äº«ç‹€æ…‹**ï¼š`ngx.now()`ï¼ˆç•¶å‰æ™‚é–“ï¼‰ã€`ngx.timer.at()`ï¼ˆæ’ç¨‹èƒŒæ™¯ä»»å‹™ï¼‰ã€`ngx.shared.DICT`ï¼ˆè·¨è«‹æ±‚å…±äº«è¨˜æ†¶é«”ï¼‰ã€‚

> âš ï¸ **é‡è¦é™åˆ¶**ï¼š`balancer_by_lua*` éšæ®µç„¡æ³•ä½¿ç”¨ `ngx.socket.tcp()` ç­‰ cosocket APIï¼Œå› æ­¤ç„¡æ³•åœ¨æ­¤éšæ®µé€²è¡Œè³‡æ–™åº«æŸ¥è©¢æˆ– DNS è§£æã€‚é€™å°±æ˜¯ç‚ºä»€éº¼æœ¬å°ˆæ¡ˆæ¡ç”¨å…©éšæ®µæ¶æ§‹çš„åŸå› ã€‚

æœ¬å°ˆæ¡ˆä¸­ï¼Œ**è«‹æ±‚å¯¦éš›å°å‘å“ªä¸€å€‹ `uptime-kuma-nodeX`ï¼Œç”±å…©éšæ®µå”ä½œå®Œæˆ**ï¼š
1. **Access éšæ®µ**ï¼š`access_by_lua_block` + `monitor_router.preselect_node()` æŸ¥è©¢ DBã€è§£æ DNSã€å­˜å…¥ `ngx.ctx`
2. **Balancer éšæ®µ**ï¼š`balancer_by_lua_block` + `monitor_router.get_preselected_node()` è®€å– `ngx.ctx`ã€å‘¼å« `ngx.balancer.set_current_peer()`

### 1\. config.lua - é›†ä¸­é…ç½®ç®¡ç†

æ‰€æœ‰ç’°å¢ƒè®Šæ•¸å’Œé è¨­å€¼é›†ä¸­ç®¡ç†ï¼Œé¿å…ç¡¬ç·¨ç¢¼ï¼š

```lua
local config = require "config"

-- è³‡æ–™åº«é…ç½®
config.database.host      -- DB_HOST
config.database.port      -- DB_PORT
config.database.user      -- DB_USER
config.database.password  -- DB_PASSWORD
config.database.database  -- DB_NAME

-- é›†ç¾¤é…ç½®
config.cluster.node_count              -- CLUSTER_NODE_COUNT (é è¨­: 3)
config.cluster.monitor_limit_per_node  -- MONITOR_LIMIT_PER_NODE (é è¨­: 1000)

-- å¥åº·æª¢æŸ¥é…ç½®
config.health_check.interval  -- HEALTH_CHECK_INTERVAL (é è¨­: 30ç§’)
config.health_check.timeout   -- HEALTH_CHECK_TIMEOUT (é è¨­: 5000ms)
```

### 2\. db.lua - å…±ç”¨è³‡æ–™åº«æ¨¡çµ„

çµ±ä¸€çš„è³‡æ–™åº«é€£æ¥é‚è¼¯ï¼Œæ¶ˆé™¤é‡è¤‡ä»£ç¢¼ï¼š

```lua
local db = require "db"

-- å»ºç«‹é€£æ¥
local conn, err = db.connect()

-- åŸ·è¡ŒæŸ¥è©¢ä¸¦è‡ªå‹•é—œé–‰
local res, err = db.query("SELECT * FROM node")
```

### 3\. logger.lua - å…±ç”¨æ—¥èªŒæ¨¡çµ„

çµ±ä¸€çš„æ—¥èªŒæ ¼å¼å’Œåˆ†é¡ï¼š

```lua
local logger = require "logger"

-- åˆ†é¡æ—¥èªŒ
logger.health_check("Node 1 is online")
logger.database("Query executed: %s", sql)
logger.router("Selected node: %s", node_id)
logger.debug("CATEGORY", "Debug info: %s", data)
```

### 4\. middleware.lua - ä¸­ä»‹å±¤æ¨¡çµ„

çµ±ä¸€è™•ç† access å’Œ header_filter éšæ®µï¼Œæ¸›å°‘ nginx.conf é‡è¤‡ä»£ç¢¼ï¼š

```lua
local middleware = require "middleware"

-- Access éšæ®µï¼šé é¸ç¯€é»
middleware.preselect_node()

-- Header Filter éšæ®µï¼šæ·»åŠ è·¯ç”±æ¨™é ­
middleware.add_routing_headers()
```

### 5\. monitor_router.lua - è·¯ç”±æ±ºç­–é‚è¼¯

è² è²¬é¸æ“‡è¦æŠŠè«‹æ±‚è½‰ç™¼åˆ°å“ªå€‹ Uptime Kuma ç¯€é»ã€‚

#### ç‚ºä»€éº¼è¦ã€Œå…©éšæ®µã€ï¼Ÿ

å› ç‚º OpenResty çš„ `balancer_by_lua` éšæ®µ**ç¦æ­¢ä½¿ç”¨ç¶²è·¯é€£ç·š**ï¼Œæ‰€ä»¥ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Access éšæ®µ    â”‚ â”€â”€â–¶  â”‚  Balancer éšæ®µ   â”‚
â”‚  (å¯ä»¥æŸ¥ DB)    â”‚      â”‚  (åªèƒ½è¨­ç›®æ¨™)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. æŸ¥ DB é¸ç¯€é» â”‚      â”‚ è®€å– ngx.ctx     â”‚
â”‚ 2. DNS è§£ææˆ IPâ”‚      â”‚ è¨­å®š IP:Port     â”‚
â”‚ 3. å­˜åˆ° ngx.ctx â”‚      â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ä¸»è¦å‡½æ•¸

| å‡½æ•¸ | ç”¨é€” |
|:---|:---|
| `preselect_node()` | ã€Access éšæ®µã€‘æŸ¥ DB é¸ç¯€é» â†’ è§£æ DNS â†’ å­˜å…¥ `ngx.ctx` |
| `get_preselected_node()` | ã€Balancer éšæ®µã€‘å¾ `ngx.ctx` è®€å– IP:Port |
| `pick_node_for_request()` | æŸ¥è©¢æœ€ç©ºé–’çš„ online ç¯€é» |
| `resolve_host()` | å°‡ Docker æœå‹™åè§£æç‚º IP |
| `get_cluster_status()` | å–å¾—é›†ç¾¤ç‹€æ…‹ |
| `get_node_capacity()` | å–å¾—ç¯€é»å®¹é‡ |

### 6\. health_check.lua - å¥åº·æª¢æŸ¥æ¨¡çµ„

è² è²¬ç¶­è­·é›†ç¾¤ç©©å®šæ€§èˆ‡æ•…éšœè™•ç†ã€‚

#### æ ¸å¿ƒè·è²¬

- **ç¯€é»å¥åº·æª¢æŸ¥**ï¼šå®šæœŸå°æ¯å€‹ç¯€é»çš„ `/api/v1/health` ç™¼å‡º HTTP æª¢æŸ¥
- **æ•…éšœæª¢æ¸¬èˆ‡è½‰ç§»**ï¼šç•¶ç¯€é»é€£çºŒå¤šæ¬¡æª¢æŸ¥å¤±æ•—æ™‚ï¼Œæ¨™è¨˜ç‚º `offline` ä¸¦é‡æ–°åˆ†é…ç›£æ§ä»»å‹™
- **ç¯€é»æ¢å¾©**ï¼šç¯€é»æ¢å¾©å¥åº·å¾Œï¼Œé‚„åŸå…ˆå‰è½‰ç§»çš„ç›£æ§ä»»å‹™

#### é—œéµå‡½æ•¸

| å‡½æ•¸ | ç”¨é€” |
|:---|:---|
| `run_health_check()` | åŸ·è¡Œå–®æ¬¡å¥åº·æª¢æŸ¥æµç¨‹ |
| `health_check_worker()` | é€±æœŸæ€§å¥åº·æª¢æŸ¥èƒŒæ™¯å·¥ä½œ |
| `redistribute_monitors_from_node()` | æ•…éšœè½‰ç§»ï¼šé‡æ–°åˆ†é…ç›£æ§ä»»å‹™ |
| `revert_monitors_to_node()` | ç¯€é»æ¢å¾©ï¼šé‚„åŸç›£æ§ä»»å‹™ |
| `get_all_nodes()` | æŸ¥è©¢æ‰€æœ‰ç¯€é»ç‹€æ…‹ |
| `update_node_status()` | æ›´æ–°ç¯€é»ç‹€æ…‹åˆ°è³‡æ–™åº« |

-----

## ğŸŒ API æ¥å£ | API Endpoints

OpenResty æä¾›äº†ä¸€ç³»åˆ— HTTP API ç”¨æ–¼ç›£æ§ç‹€æ…‹èˆ‡ç®¡ç†é›†ç¾¤ã€‚
> OpenResty provides a series of HTTP APIs for monitoring status and managing the cluster.

### ğŸ” ç‹€æ…‹ç›£æ§ | Status Monitoring

| æ–¹æ³• | è·¯å¾‘ | æè¿° |
| :--- | :--- | :--- |
| `GET` | `/health` | è¿”å› Nginx è² è¼‰å¹³è¡¡å™¨æœ¬èº«çš„å¥åº·ç‹€æ…‹èˆ‡æ™‚é–“æˆ³ã€‚ |
| `GET` | `/api/system-status` | **æ¨è–¦**ï¼šè¿”å›æ‰€æœ‰æ¨¡çµ„çš„ç¶œåˆç‹€æ…‹è³‡è¨Šï¼ˆåŒ…å«ç¯€é»ã€è² è¼‰ã€æ•…éšœæª¢æ¸¬ï¼‰ã€‚ |
| `GET` | `/api/node-status` | è¿”å›æ‰€æœ‰å¾Œç«¯ç¯€é»çš„è©³ç´°ç‹€æ…‹ï¼ˆOnline/Offline/Recoveringï¼‰ã€‚ |
| `GET` | `/api/load-balancer-status` | æŸ¥çœ‹ç¯€é»è² è¼‰åˆ†æ•¸ã€æœ€å¾Œæ›´æ–°æ™‚é–“ã€‚ |
| `GET` | `/api/health-check-status` | æŸ¥çœ‹å¿ƒè·³çµ±è¨ˆã€æ•…éšœè½‰ç§»æ­·å²è¨˜éŒ„ã€‚ |
| `GET` | `/api/fault-detection-status` | æŸ¥çœ‹æ•…éšœæª¢æ¸¬æƒæå™¨çš„é‹è¡Œçµ±è¨ˆã€‚ |

### ğŸ¯ å›ºå®šç¯€é»è·¯ç”± | Fixed Node Routing

| æ–¹æ³• Method | è·¯å¾‘ Path | æè¿° Description |
| :--- | :--- | :--- |
| `GET` | `/lb/fixed-node/{node}` | è¨­å®šå›ºå®šç¯€é»ï¼ˆHTML é é¢ï¼‰/ Set fixed node (HTML page) |
| `GET` | `/lb/clear-fixed-node` | æ¸…é™¤å›ºå®šç¯€é»ï¼ˆHTML é é¢ï¼‰/ Clear fixed node (HTML page) |
| `POST` | `/lb/set-fixed-node` | è¨­å®šå›ºå®šç¯€é»ï¼ˆJSON APIï¼‰/ Set fixed node (JSON API) |
| `POST` | `/lb/clear-fixed-node` | æ¸…é™¤å›ºå®šç¯€é»ï¼ˆJSON APIï¼‰/ Clear fixed node (JSON API) |
| `GET` | `/lb/fixed-node-status` | æŸ¥çœ‹ç•¶å‰å›ºå®šç¯€é»ç‹€æ…‹ / View current fixed node status |
| `GET` | `/lb/available-nodes` | åˆ—å‡ºæ‰€æœ‰å¯ç”¨ç¯€é» / List all available nodes |

### âš™ï¸ ç®¡ç†èˆ‡æ“ä½œ | Management & Operations

| æ–¹æ³• | è·¯å¾‘ | æè¿° |
| :--- | :--- | :--- |
| `GET` | `/api/update-loads` | æ‰‹å‹•å¼·åˆ¶æ›´æ–°è² è¼‰è³‡è¨Šã€‚ |
| `GET` | `/api/trigger-rebalancing` | æ‰‹å‹•è§¸ç™¼ä¸€æ¬¡ç›£æ§å™¨é‡æ–°å¹³è¡¡ã€‚ |
| `GET` | `/api/force-rebalance-all` | **å±éšª**ï¼šå¼·åˆ¶é‡æ–°åˆ†é…æ‰€æœ‰ç›£æ§å™¨ï¼ˆç”¨æ–¼é›†ç¾¤åš´é‡ä¸å¹³è¡¡æ™‚ï¼‰ã€‚ |
| `GET` | `/api/rebalancing-status` | æŸ¥çœ‹ç•¶å‰é‡æ–°å¹³è¡¡æ“ä½œçš„é€²åº¦èˆ‡çµ±è¨ˆã€‚ |

-----

## âš™ï¸ é…ç½®èªªæ˜ | Configuration

### 1\. ç’°å¢ƒè®Šæ•¸ | Environment Variables

è«‹ç¢ºä¿ Nginx é‹è¡Œç’°å¢ƒä¸­åŒ…å«ä»¥ä¸‹è®Šæ•¸ï¼ˆæ¨è–¦åœ¨ `nginx.conf` æˆ– Docker `env` ä¸­è¨­ç½®ï¼‰ï¼š

```bash
# è³‡æ–™åº«é…ç½® (ç”¨æ–¼ Lua é€£æ¥ MariaDB)
DB_HOST=mariadb
DB_PORT=3306
DB_USER=kuma
DB_PASSWORD=kuma_pass
DB_NAME=kuma

# æœ¬åœ°ç¯€é»æ¨™è­˜
UPTIME_KUMA_NODE_ID=nginx-node
UPTIME_KUMA_NODE_HOST=127.0.0.1
```

### 2\. Nginx å…±äº«è¨˜æ†¶é«” | Nginx Shared Memory

åœ¨ `nginx.conf` çš„ `http` å€å¡Šä¸­å®šç¾© Lua å…±äº«å­—å…¸ï¼ˆç¯€éŒ„ï¼‰ï¼š

```nginx
http {
    # ...

    # å…±äº«è¨˜æ†¶é«”å€åŸŸ
    lua_shared_dict health_checker 10m;   # å­˜å„²å¥åº·æª¢æŸ¥çµæœèˆ‡çµ±è¨ˆ
    lua_shared_dict monitor_routing 10m;  # ç›£æ§ ID -> ç¯€é»çš„è·¯ç”±å¿«å–
    lua_shared_dict node_capacity 1m;     # ï¼ˆé ç•™ï¼‰ç¯€é»å®¹é‡è³‡è¨Šå¿«å–ï¼Œæœªå¿…åœ¨æ‰€æœ‰ç‰ˆæœ¬ä¸­ä½¿ç”¨

    # ...
}
```

### 3\. å®šæ™‚ä»»å‹™ | Timers

Lua è…³æœ¬ä¸­é è¨­çš„å®šæ™‚å™¨é–“éš” | Default timer intervals in Lua scripts:

| ä»»å‹™ Task | é–“éš” Interval |
| :--- | :--- |
| è² è¼‰æ›´æ–° Load Update | `30s` |
| æ•…éšœæƒæ Fault Scan | `10s` |
| å¿ƒè·³ç™¼é€ Heartbeat | `60s` |
| æ•…éšœè½‰ç§»æª¢æŸ¥ Failover Check | `60s` |

-----

## ğŸš€ éƒ¨ç½²æŒ‡å— | Deployment Guide

### å‰ç½®éœ€æ±‚ | Prerequisites

- **Nginx OpenResty** (å»ºè­°ç‰ˆæœ¬ 1.19+ | Recommended version 1.19+)
- **MariaDB/MySQL** (Uptime Kuma è³‡æ–™å­˜å„² | Data storage for Uptime Kuma)
- **Uptime Kuma** (å·²é…ç½®å¤šç¯€é»æ¨¡å¼ | Configured for multi-node mode)

### æ­¥é©Ÿ 1: éƒ¨ç½² Lua è…³æœ¬ | Step 1: Deploy Lua Scripts

å°‡ `lua` è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰æ¨¡çµ„è¤‡è£½åˆ° OpenResty çš„åº«ç›®éŒ„ï¼š

```bash
cp lua/*.lua /usr/local/openresty/lualib/
# æˆ–å€‹åˆ¥è¤‡è£½
cp lua/config.lua /usr/local/openresty/lualib/
cp lua/db.lua /usr/local/openresty/lualib/
cp lua/logger.lua /usr/local/openresty/lualib/
cp lua/middleware.lua /usr/local/openresty/lualib/
cp lua/monitor_router.lua /usr/local/openresty/lualib/
cp lua/health_check.lua /usr/local/openresty/lualib/
```

### æ­¥é©Ÿ 2: é…ç½® Nginx | Step 2: Configure Nginx

è¤‡è£½ä¸¦ä¿®æ”¹ `nginx.conf`ï¼š

```bash
cp nginx/nginx.conf /usr/local/openresty/nginx/conf/
```

ç¢ºä¿ `upstream` å¡Šæ­£ç¢ºæŒ‡å‘ä½ çš„ Uptime Kuma ç¯€é»ï¼š

```nginx
upstream uptime_kuma_backend {
    zone uptime_kuma_backend 64k;
    ip_hash; # ä½œç‚ºåŸºç¤ï¼ŒLua æœƒè¦†è“‹æ­¤æ±ºç­–
    
    server uptime-kuma-node1:3001 max_fails=3 fail_timeout=30s;
    server uptime-kuma-node2:3002 max_fails=3 fail_timeout=30s;
    server uptime-kuma-node3:3003 max_fails=3 fail_timeout=30s;
    
    keepalive 32;
}
```

### æ­¥é©Ÿ 3: å•Ÿå‹•æœå‹™ | Step 3: Start Services

```bash
# æª¢æŸ¥é…ç½®èªæ³•
nginx -t

# å•Ÿå‹•æˆ–é‡è¼‰ Nginx
nginx -s reload

# é©—è­‰ç³»çµ±ç‹€æ…‹
curl http://localhost/api/system-status
```

-----


## ğŸ§ª æ¸¬è©¦èˆ‡å·¥å…· | Testing & Tools

- **OpenResty / API åŠŸèƒ½æ¸¬è©¦**ï¼šä½¿ç”¨ `set-up.http` æª”æ¡ˆé€²è¡Œæ¸¬è©¦
  > Use `set-up.http` file for testing
- æ”¯æ´å·¥å…· | Supported tools: VS Code REST Client, IntelliJ HTTP Client, Thunder Client

## ğŸ“Š ç›£æ§èˆ‡ç¶­è­· | Monitoring & Maintenance

ç‚ºäº†ç¢ºä¿ç”Ÿç”¢ç’°å¢ƒçš„ç©©å®šæ€§ï¼Œå»ºè­°é—œæ³¨ä»¥ä¸‹æŒ‡æ¨™ï¼š
> To ensure production stability, monitor the following:

1.  **æ—¥èªŒç›£æ§ | Log Monitoring**ï¼š
    - `/usr/local/openresty/nginx/logs/error.log`: é—œæ³¨ Lua è…³æœ¬å ±éŒ¯æˆ–è³‡æ–™åº«é€£æ¥éŒ¯èª¤
    > Monitor for Lua script errors or database connection errors

2.  **API å·¡æª¢ | API Inspection**ï¼š
    - å®šæœŸèª¿ç”¨ `/api/node-status` ç¢ºä¿æ²’æœ‰ç¯€é»å¡åœ¨ `recovering` ç‹€æ…‹éä¹…
    > Regularly call `/api/node-status` to ensure no nodes are stuck in `recovering` status

3.  **æ•…éšœæ’æŸ¥ | Troubleshooting**ï¼š
    - ğŸ” **è³‡æ–™åº«é€£æ¥**ï¼šç¢ºä¿ DB å¸³è™Ÿæ¬Šé™æ­£ç¢º | Ensure DB account permissions are correct
    - ğŸ” **ç¶²çµ¡å»¶é²**ï¼šå¦‚æœå¿ƒè·³é »ç¹è¶…æ™‚ï¼Œè€ƒæ…®å¢åŠ  `timeout` è¨­å®š | If heartbeats frequently timeout, consider increasing `timeout` setting

-----

## ğŸ”’ å®‰å…¨è€ƒé‡ | Security Considerations

- **API è¨ªå•æ§åˆ¶**ï¼šå»ºè­°é€é `allow/deny` æŒ‡ä»¤é™åˆ¶ `/api/` è·¯å¾‘è¨ªå•
  > Recommend restricting `/api/` path access via `allow/deny` directives
- **è³‡æ–™åº«æ†‘è­‰**ï¼šé¿å…ç¡¬ç·¨ç¢¼å¯†ç¢¼ï¼Œå§‹çµ‚ä½¿ç”¨ `os.getenv` è®€å–ç’°å¢ƒè®Šæ•¸
  > Avoid hardcoding passwords, always use `os.getenv` to read environment variables
- **å›ºå®šç¯€é»åŠŸèƒ½**ï¼šæ­¤åŠŸèƒ½ä¸»è¦ç”¨æ–¼é–‹ç™¼èª¿è©¦ï¼Œç”Ÿç”¢ç’°å¢ƒè«‹è¬¹æ…ä½¿ç”¨
  > Fixed node feature is mainly for development debugging, use cautiously in production

-----

## â“ å¸¸è¦‹å•é¡Œ | FAQ

- **API è¿”å› 502 / 504**ï¼š
  - æª¢æŸ¥ `nginx/logs/error.log` æ˜¯å¦æœ‰ Lua æˆ–è³‡æ–™åº«é€£ç·šéŒ¯èª¤
  - ç¢ºèª `DB_*` ç’°å¢ƒè®Šæ•¸å·²æ­£ç¢ºè¨­ç½®
  > Check `nginx/logs/error.log` for Lua or database connection errors. Verify `DB_*` environment variables are set correctly.

- **ç¯€é»åè¦†æ¢å¾©/é›¢ç·šï¼ˆFlappingï¼‰**ï¼š
  - èª¿æ•´å¥åº·æª¢æŸ¥é–“éš”æˆ–è¶…æ™‚ï¼›æª¢æŸ¥ç¶²è·¯å»¶é²èˆ‡ç¯€é»è² è¼‰
  > Adjust health check interval or timeout; check network latency and node load.

- **ç›£æ§å™¨åˆ†ä½ˆä¸å‡**ï¼š
  - ä½¿ç”¨ `/api/trigger-rebalancing` æˆ– `/api/force-rebalance-all` é€²è¡Œå†å¹³è¡¡
  > Use `/api/trigger-rebalancing` or `/api/force-rebalance-all` for rebalancing.

- **å›ºå®šç¯€é»ç„¡æ•ˆ**ï¼š
  - æª¢æŸ¥ç¯€é»æ˜¯å¦åœ¨ç·šï¼šè¨ªå• `/lb/available-nodes`
  - æ¸…é™¤ Cookieï¼šè¨ªå• `/lb/clear-fixed-node`
  > Check if node is online: visit `/lb/available-nodes`. Clear Cookie: visit `/lb/clear-fixed-node`.

-----

## ğŸ“š ç›¸é—œæ–‡ä»¶ | Related Documents

| æ–‡ä»¶ Document | èªªæ˜ Description |
| :--- | :--- |
| `API_DOCUMENTATION.md` | å®Œæ•´ API è¦ç¯„èˆ‡ç¤ºä¾‹ / Complete API specification and examples |
| `CLUSTER_DEPLOYMENT_GUIDE.md` | é›†ç¾¤éƒ¨ç½²èˆ‡æ“ä½œæŒ‡å— / Cluster deployment and operation guide |
| `PUBLIC_STATUS_PAGINATION_PLAN.md` | å…¬é–‹ç‹€æ…‹é åˆ†é è¨ˆç•« / Public status page pagination plan |
| `SECURITY.md` | å®‰å…¨è¦ç¯„ / Security guidelines |
| `CODE_OF_CONDUCT.md` | è¡Œç‚ºæº–å‰‡ / Code of conduct |
| `CONTRIBUTING.md` | è²¢ç»æŒ‡å— / Contributing guide |

-----

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

